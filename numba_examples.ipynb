{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.矩阵乘法的例子（尚未理解）**可能我对shared memory有误解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一个低效率的矩阵乘法的CUDA kernel，因为相同的矩阵元素会被device内存中被反复load很多次\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def matmul(A,B,C): #A,B,C为C=A*B\n",
    "    i,j=cuda.grid(2) #返回线程的在x和y方向的位置\n",
    "    if i<C.shape[0] and j<C.shape[1]: #申请的多余的线程舍弃掉不用\n",
    "        tmp=0\n",
    "        for k in range(A.shape[1]): #在A的列与B的行上循环\n",
    "            tmp+=A[i,k]*B[k,j] #矩阵乘法的算法\n",
    "        C[i,j]=tmp #思想：只需从矩阵的单一元素的视角出发\n",
    "#总是从矩阵单一元素的视角出发是正确的理解方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基于blocked的高效率的矩阵乘法的CUDA kernel，\n",
    "#blocked算法是利用block内的shared memory来减少对device memory的访问，从而加速。\n",
    "from numba import cuda, float32\n",
    "#block内线程为16*16\n",
    "TPB = 16\n",
    "@cuda.jit\n",
    "def fast_matmul(A,B,C):\n",
    "    SA=cuda.shared.array(shape=(TPB,TPB),dtype=float32) #定义block内shared memory的array，array的size\n",
    "    SB=cuda.shared.array(shape=(TPB,TPB),dtype=float32) #和type必须设定，注意关键字shape为元组\n",
    "    x,y=cuda.grid(2)\n",
    "    tx=cuda.threadIdx.x #二维block上\n",
    "    ty=cuda.threadIdx.y #线程的索引\n",
    "    bpg=cuda.gridDim.x #每个grid内x方向上block的数量，为何只有x方向上的block数量？可能我还是不理解shared memory吧\n",
    "    if x>=C.shape[0] and y>=C.shape[1]:\n",
    "        return #当线程索引超过矩阵的最大尺寸时，结束运算，即申请的多余的线程舍弃掉不用\n",
    "    tmp=0\n",
    "    for i in range(bpg): #对x方向上的每个block循环，为何只有x方向上的block数量？可能我还是不理解shared memory吧\n",
    "        SA[tx,ty]=A[x,ty+i*TPB] #预加载数据至shared memory。需要画图再理解一下这个地址的对应关系？\n",
    "        SB[tx,ty]=B[tx+i*TPB,y]\n",
    "        cuda.syncthreads() #等待所有线程完成预载入，强制同步\n",
    "        for j in range(TPB): #对block内的线程进行计算，这步可以利用shared memory加速\n",
    "            tmp+=SA[tx,j]*SB[j,ty]\n",
    "        cuda.syncthreads() #在进入下一个block的计算之前等待当前block内所有线程完成计算，强制同步\n",
    "    C[x,y]=tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
